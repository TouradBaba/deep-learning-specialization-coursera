# Deep Learning Specialization - Programming Assignments

This repository contains the programming assignments for the [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) by deeplearning.AI, taught by Andrew Ng. The specialization includes five comprehensive courses, each with hands-on assignments designed to help you gain practical experience with deep learning. 

**Note:** The "Structuring Machine Learning Projects" course is not included in this repository as it does not have programming assignments.

## Table of Contents

1. [Neural Networks and Deep Learning](#1-neural-networks-and-deep-learning)
2. [Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization](#2-improving-deep-neural-networks-hyperparameter-tuning-regularization-and-optimization)
3. [Convolutional Neural Networks](#3-convolutional-neural-networks)
4. [Sequence Models](#4-sequence-models)

## 1. Neural Networks and Deep Learning

### Week 2:
- [Logistic Regression with a Neural Network Mindset](1-Neural_Networks_and_Deep_Learning/Week-2/Logistic_Regression_with_a_Neural_Network_mindset.ipynb)

### Week 3:
- [Planar Data Classification with One Hidden Layer](1-Neural_Networks_and_Deep_Learning/Week-3/Planar_data_classification_with_one_hidden_layer.ipynb)

### Week 4:
- [Building Your Deep Neural Network: Step by Step](1-Neural_Networks_and_Deep_Learning/Week-4/1-Building_your_Deep_Neural_Network_Step_by_Step.ipynb)
- [Deep Neural Network - Application](1-Neural_Networks_and_Deep_Learning/Week-4/2-Deep_Neural_Network-Application.ipynb)

## 2. Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization

### Week 1:
- [Initialization](2-Improving_Deep_Neural_Networks_Hyperparameter_Tuning,Regularization_and_Optimization/Week-1/1-Initialization.ipynb)
- [Regularization](2-Improving_Deep_Neural_Networks_Hyperparameter_Tuning,Regularization_and_Optimization/Week-1/2-Regularization.ipynb)
- [Gradient Checking](2-Improving_Deep_Neural_Networks_Hyperparameter_Tuning,Regularization_and_Optimization/Week-1/3-Gradient_Checking.ipynb)

### Week 2:
- [Optimization Methods](2-Improving_Deep_Neural_Networks_Hyperparameter_Tuning,Regularization_and_Optimization/Week-2/Optimization_methods.ipynb)

### Week 3:
- [TensorFlow Introduction](2-Improving_Deep_Neural_Networks_Hyperparameter_Tuning,Regularization_and_Optimization/Week-3/Tensorflow_introduction.ipynb)

## 3. Convolutional Neural Networks

### Week 1:
- [Convolutional Model: Step by Step v1](3-Convolutional_Neural_Networks/Week-1/1-Convolution_model_Step_by_Step_v1.ipynb)
- [Convolutional Model: Application](3-Convolutional_Neural_Networks/Week-1/2-Convolution_model_Application.ipynb)

### Week 2:
- [Residual Networks](3-Convolutional_Neural_Networks/Week-2/1-Residual_Networks.ipynb)
- [Transfer Learning with MobileNet v1](3-Convolutional_Neural_Networks/Week-2/2-Transfer_learning_with_MobileNet_v1.ipynb)

### Week 3:
- [Autonomous Driving Application: Car Detection](3-Convolutional_Neural_Networks/Week-3/1-Autonomous_driving_application_Car_detection.ipynb)
- [Image Segmentation with U-Net v2](3-Convolutional_Neural_Networks/Week-3/2-Image_segmentation_Unet_v2.ipynb)

### Week 4:
- [Face Recognition](3-Convolutional_Neural_Networks/Week-4/1-Face_Recognition.ipynb)
- [Art Generation with Neural Style Transfer](3-Convolutional_Neural_Networks/Week-4/2-Art_Generation_with_Neural_Style_Transfer.ipynb)

## 4. Sequence Models

### Week 1:
- [Building a Recurrent Neural Network: Step by Step](4-Sequence_Models/Week-1/1-Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb)
- [Dinosaurus Island: Character-level Language Model](4-Sequence_Models/Week-1/2-Dinosaurus_Island_Character_level_language_model.ipynb)
- [Improvise a Jazz Solo with an LSTM Network v4](4-Sequence_Models/Week-1/3-Improvise_a_Jazz_Solo_with_an_LSTM_Network_v4.ipynb)

### Week 2:
- [Operations on Word Vectors v2a](4-Sequence_Models/Week-2/1-Operations_on_word_vectors_v2a.ipynb)
- [Emoji v3a](4-Sequence_Models/Week-2/2-Emoji_v3a.ipynb)

### Week 3:
- [Neural Machine Translation with Attention v4a](4-Sequence_Models/Week-3/1-Neural_machine_translation_with_attention_v4a.ipynb)
- [Trigger Word Detection v2a](4-Sequence_Models/Week-3/2-Trigger_word_detection_v2a.ipynb)

### Week 4:
- [Transformer Subclass v1](4-Sequence_Models/Week-4/C5_W4_A1_Transformer_Subclass_v1.ipynb)

#### Ungraded Labs:
- [Embedding plus Positional Encoding](4-Sequence_Models/Week-4/Ungraded_Labs/1-Embedding_plus_Positional_encoding.ipynb)
- [Transformer Application: Named Entity Recognition](Week-4/Ungraded_Labs/2-Transformer_application_Named_Entity_Recognition.ipynb)
- [QA Dataset](Ungraded_Labs/Week-4/3-QA_dataset.ipynb)


## Acknowledgements

These assignments are part of the Deep Learning Specialization by deeplearning.AI on Coursera, taught by Andrew Ng. All credit for the course content goes to the creators of the specialization.


